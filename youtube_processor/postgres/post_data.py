from .models import Token, Script, ScriptWord, URL, Actor # URL, Actor ëª¨ë¸ import ì¶”ê°€
from .mfcc import extract_mfcc_from_audio, extract_mfcc_segment # MFCC ë°ì´í„° ì¶”ê°€


import time
from typing import Optional
from sqlalchemy.orm import Session
from sqlalchemy.exc import OperationalError, ProgrammingError
import traceback
import numpy as np

def insert_token_with_sentences(db: Session, 
                                token_data: dict, 
                                sentences_data: list[dict],
                                mfcc_mat: np.ndarray,
                                frame_times: np.ndarray
                                ):
    """
    í•˜ë‚˜ì˜ Tokenê³¼ ê·¸ì— ì†í•œ ì—¬ëŸ¬ ScriptSentenceë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê³ ,
    ê° ë‹¨ì–´ë³„ë¡œ MFCCë¥¼ ìŠ¬ë¼ì´ìŠ¤í•˜ì—¬ ScriptWord.mfccì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        # Token ê°ì²´ ìƒì„±
        new_token = Token(**token_data)

        # Token ë¨¼ì € ì„¸ì…˜ì— ì¶”ê°€
        db.add(new_token)

        
        for sentence_dict in sentences_data:
            words = sentence_dict.pop("words", [])  # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            sentence = Script(**sentence_dict)
            sentence.token = new_token
            db.add(sentence)

            for word in words:
                # ë‹¨ì–´ë³„ë¡œ MFCC ì¶”ì¶œ
                start, end = word["start"], word["end"]
                segment_mfcc = extract_mfcc_segment(
                    mfcc_mat, frame_times, start_time=start, end_time=end
                ).tolist()

                word_entry = ScriptWord(
                    word=word["word"].strip(),
                    start_time=word["start"],
                    end_time=word["end"],
                    probability = float(word.get("probability", 0.0)),
                    mfcc=segment_mfcc,  
                    script=sentence  # ê´€ê³„ ì—°ê²°
                )
                db.add(word_entry)

        print("ğŸ¯ Token ë°ì´í„°:", repr(token_data))
        print("ğŸ¯ Sentence ë°ì´í„°:\n", [repr(s) for s in sentences_data])

        # ì»¤ë°‹ ë° ë°˜ì˜
        db.commit()
        db.refresh(new_token)

        print(f"âœ… Token ë° ë¬¸ì¥ ì‚½ì… ì„±ê³µ: token_id={new_token.id}")
        return new_token

    except Exception as e:
        db.rollback()
        print("âŒ ì‚½ì… ì‹¤íŒ¨:")
        traceback.print_exc()  # ìƒì„¸ ì—ëŸ¬ ì¶”ì  ì¶œë ¥
        return None


def make_token(db: Session, 
               movie_name: str, 
               actor_name: str, 
               speaker: dict,
               audio_path:str,
               s3_textgrid_url: str, 
               s3_pitch_url: str, 
               s3_bgvoice_url: str):
    
    """
    Token ìƒì„± ì „, ì „ì²´ ì˜¤ë””ì˜¤ì—ì„œ MFCC í–‰ë ¬ê³¼ í”„ë ˆì„ íƒ€ì„ì„ ì¶”ì¶œ í›„
    insert_token_with_sentences ì— ì „ë‹¬í•©ë‹ˆë‹¤.
    """

    # --- Actor ì¡°íšŒ ë˜ëŠ” ìƒì„± ---
    actor = db.query(Actor).filter(Actor.name == actor_name).first()
    if not actor:
        actor = Actor(name=actor_name)
        db.add(actor)
        db.flush() # Actor IDë¥¼ ì–»ê¸° ìœ„í•´ flush (ì•„ì§ commit ì•„ë‹˜)
        print(f"âœ… ìƒˆë¡œìš´ Actor ìƒì„±: {actor_name} (ID: {actor.id})")
    else:
        print(f"âœ… ê¸°ì¡´ Actor ì‚¬ìš©: {actor_name} (ID: {actor.id})")

    # --- URL ì¡°íšŒ ë˜ëŠ” ìƒì„± ---
    youtube_url_str = speaker["video_url"]
    url_entry = db.query(URL).filter(URL.youtube_url == youtube_url_str).first()
    if not url_entry:
        url_entry = URL(youtube_url=youtube_url_str, actor_id=actor.id)
        db.add(url_entry)
        db.flush() # URL IDë¥¼ ì–»ê¸° ìœ„í•´ flush (ì•„ì§ commit ì•„ë‹˜)
        print(f"âœ… ìƒˆë¡œìš´ URL ìƒì„±: {youtube_url_str}")
    else:
        print(f"âœ… ê¸°ì¡´ URL ì‚¬ìš©: {youtube_url_str}")

    # ì „ì²´ ì˜¤ë””ì˜¤ì—ì„œ MFCCì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (ì˜ë¦° ì˜¤ë””ì˜¤ ê¸°ì¤€)
    mfcc_mat, frame_times = extract_mfcc_from_audio(audio_path)
    
    # start_timeì´ ìˆìœ¼ë©´ frame_times ì¡°ì • (ë‹¨ì–´ ì‹œê°„ê³¼ ë§ì¶”ê¸°)
    start_time_offset = float(speaker.get("start_time", 0))
    if start_time_offset > 0:
        print(f"[DEBUG] MFCC ì¶”ì¶œ í›„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì •: +{start_time_offset}ì´ˆ ì¶”ê°€")
        # frame_timesì— start_time_offset ì¶”ê°€
        frame_times = frame_times + start_time_offset
        print(f"[DEBUG] ì¡°ì •ëœ frame_times ë²”ìœ„: {frame_times[0]:.3f}~{frame_times[-1]:.3f}ì´ˆ")

    token_data = {
        "token_name": movie_name if movie_name is not None else "", # None ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´
        "actor_name": actor_name if actor_name is not None else "", # None ëŒ€ì‹  ë¹ˆ ë¬¸ìì—´
        "category": "romance",
        "start_time": float(speaker["start_time"]),
        "end_time": float(speaker["end_time"]),
        "s3_textgrid_url": s3_textgrid_url,
        "s3_pitch_url": s3_pitch_url,
        "s3_bgvoice_url": s3_bgvoice_url,
        "youtube_url": youtube_url_str # URL ê°ì²´ ëŒ€ì‹  ë¬¸ìì—´ ì‚¬ìš©
        # view_countëŠ” models.pyì— default=0ì´ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•  í•„ìš” ì—†ìŒ
    }

    sentences_data = []
    for seg in speaker.get("segments", []):
        try:
            script_clean = seg["text"].encode("utf-8", errors="replace").decode("utf-8")
            sentence_entry = {
                "script": script_clean,
                'start_time': float(seg['start']),
                'end_time': float(seg['end']),
                "words": seg.get("words", [])
            }
            sentences_data.append(sentence_entry)
        except Exception as e:
            print(f"âŒ ë¬¸ì¥ ì¸ì½”ë”© ì‹¤íŒ¨: {repr(seg['text'])}")
            traceback.print_exc()

    # mfcc_mat, frame_times ì¶”ê°€
    return insert_token_with_sentences(db, token_data, sentences_data, mfcc_mat, frame_times)
