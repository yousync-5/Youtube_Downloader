from .models import Token, ScriptSentence, ScriptWord
from sqlalchemy.orm import Session
import traceback  # â† ì—ëŸ¬ ì¶œë ¥ìš©
import numpy as np

def insert_token_with_sentences(db: Session, token_data: dict, sentences_data: list[dict]):
    """
    í•˜ë‚˜ì˜ Tokenê³¼ ê·¸ì— ì†í•œ ì—¬ëŸ¬ ScriptSentenceë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    try:
        # Token ê°ì²´ ìƒì„±
        new_token = Token(**token_data)

        # Token ë¨¼ì € ì„¸ì…˜ì— ì¶”ê°€
        db.add(new_token)

        
        for sentence_dict in sentences_data:
            words = sentence_dict.pop("words", [])  # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            sentence = ScriptSentence(**sentence_dict)
            sentence.token = new_token
            db.add(sentence)

            for word in words:
                word_entry = ScriptWord(
                    word=word["word"].strip(),
                    start_time=word["start"],
                    end_time=word["end"],
                    # probability = float(word.get("probability", 0.0)),  
                    sentence=sentence  # ê´€ê³„ ì—°ê²°
                )
                db.add(word_entry)

        print("ğŸ¯ Token ë°ì´í„°:", repr(token_data))
        print("ğŸ¯ Sentence ë°ì´í„°:", [repr(s) for s in sentences_data])

        # ì»¤ë°‹ ë° ë°˜ì˜
        db.commit()
        db.refresh(new_token)

        print(f"âœ… Token ë° ë¬¸ì¥ ì‚½ì… ì„±ê³µ: token_id={new_token.id}")
        return new_token

    except Exception as e:
        db.rollback()
        print("âŒ ì‚½ì… ì‹¤íŒ¨:")
        traceback.print_exc()  # ìƒì„¸ ì—ëŸ¬ ì¶”ì  ì¶œë ¥
        return None


def make_token(db: Session, actor_name: str, speaker: dict,
               s3_textgrid_url: str, s3_pitch_url: str, s3_bgvoice_url: str):
    token_data = {
        "token_name": "í™•ì¸ìš©",
        "actor_name": actor_name,
        "category": "ìŠ¤ë¦´ëŸ¬",  # ë§Œì•½ Token ëª¨ë¸ì— 'category' ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì´ ì¤„ ì‚­ì œ í•„ìš”
        "start_time": float(speaker["start_time"]),  # numpy â†’ float ë³€í™˜
        "end_time": float(speaker["end_time"]),
        "s3_textgrid_url": s3_textgrid_url,
        "s3_pitch_url": s3_pitch_url,
        "s3_bgvoice_url": s3_bgvoice_url,
        "youtube_url": speaker["video_url"]
    }

    sentences_data = []
    for seg in speaker.get("segments", []):
        try:
            script_clean = seg["text"].encode("utf-8", errors="replace").decode("utf-8")
            sentence_entry = {
                "script": script_clean,
                'start_time': float(np.float64(3.98)),       # ğŸ”§ ë°˜ë“œì‹œ float() ì²˜ë¦¬
                'end_time': float(np.float64(24.66)),
                "words": seg.get("words", [])
            }
            sentences_data.append(sentence_entry)
        except Exception as e:
            print(f"âŒ ë¬¸ì¥ ì¸ì½”ë”© ì‹¤íŒ¨: {repr(seg['text'])}")
            traceback.print_exc()

    return insert_token_with_sentences(db, token_data, sentences_data)
