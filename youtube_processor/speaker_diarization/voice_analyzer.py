# voice_analyzer.py
from resemblyzer import VoiceEncoder, preprocess_wav
import numpy as np
import os
from tempfile import NamedTemporaryFile
from pydub import AudioSegment
from sklearn.cluster import KMeans

# ì„¸ê·¸ë¨¼íŠ¸ ë³„ë¡œ ìŒì„± ì˜ë¼ë‚´ê¸° (wav ë‹¨ìœ„)
# def extract_segment_audio(full_audio_path, start, end):
#     audio = AudioSegment.from_wav(full_audio_path)
def extract_segment_audio(full_audio_path, start, end):
    # MP3ë“  WAVë“  í¬ë§· ìë™ ê°ì§€
    audio = AudioSegment.from_file(full_audio_path)
    segment_audio = audio[start * 1000:end * 1000]  # pydub: milliseconds ë‹¨ìœ„

    tmp = NamedTemporaryFile(delete=False, suffix=".wav")
    segment_audio.export(tmp.name, format="wav")
    return tmp.name

def analyze_voice_speakers(vocal_audio_path: str, segments: list[dict], threshold: float = 0.75):
    encoder = VoiceEncoder()

    print("\nğŸ”Š Resemblyzer ë¡œë”© ì™„ë£Œ, ìŒì„± í™”ì ë¶„ì„ ì‹œì‘...")
    segment_embeddings = []

    for i, seg in enumerate(segments):
        try:
            seg_wav_path = extract_segment_audio(vocal_audio_path, seg.get('start', 0), seg.get('end', 0))
            wav = preprocess_wav(seg_wav_path)
            embed = encoder.embed_utterance(wav)
            segment_embeddings.append(embed)
            os.remove(seg_wav_path)
        except Exception as e:
            print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {i}: ìŒì„± ì¶”ì¶œ ì‹¤íŒ¨ â†’ {e}")
            segment_embeddings.append(None)

    # ì„¸ê·¸ë¨¼íŠ¸ ê°„ í™”ì ë¹„êµ
    for i in range(1, len(segment_embeddings)):
        prev = segment_embeddings[i - 1]
        curr = segment_embeddings[i]

        if prev is None or curr is None:
            print(f"ğŸ‘‚ ì„¸ê·¸ë¨¼íŠ¸ {i-1} â†” {i} â†’ âš ï¸ ë¹„êµ ë¶ˆê°€ (ë°ì´í„° ì—†ìŒ)")
            continue

        similarity = np.dot(prev, curr) / (np.linalg.norm(prev) * np.linalg.norm(curr))
        same = similarity > threshold
        print(f"ğŸ‘‚ ì„¸ê·¸ë¨¼íŠ¸ {i-1} â†” {i} â†’ {'âœ… ê°™ì€ í™”ì' if same else 'âŒ ë‹¤ë¥¸ í™”ì'} (cosine similarity: {similarity:.3f})")

def analyze_voice_speakers_with_clustering(vocal_audio_path: str, segments: list[dict], n_speakers: int = 2):
    """
    ì„¸ê·¸ë¨¼íŠ¸ë³„ ìŒì„± ì„ë² ë”©ì„ ì¶”ì¶œí•˜ê³ , KMeansë¡œ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ í™”ì ë¼ë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    encoder = VoiceEncoder()
    print("\nğŸ”Š Resemblyzer ë¡œë”© ì™„ë£Œ, ìŒì„± í™”ì í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘...")
    segment_embeddings = []

    for i, seg in enumerate(segments):
        try:
            seg_wav_path = extract_segment_audio(vocal_audio_path, seg.get('start', 0), seg.get('end', 0))
            wav = preprocess_wav(seg_wav_path)
            embed = encoder.embed_utterance(wav)
            segment_embeddings.append(embed)
            os.remove(seg_wav_path)
        except Exception as e:
            print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {i}: ìŒì„± ì¶”ì¶œ ì‹¤íŒ¨ â†’ {e}")
            segment_embeddings.append(None)

    # None ê°’ ì œê±° ë° ì¸ë±ìŠ¤ ë§¤í•‘
    valid_indices = [i for i, emb in enumerate(segment_embeddings) if emb is not None]
    valid_embeddings = [emb for emb in segment_embeddings if emb is not None]

    if not valid_embeddings:
        print("âŒ ìœ íš¨í•œ ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return ["UNKNOWN"] * len(segments), None

    # KMeans í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=n_speakers, random_state=42, n_init="auto")
    labels = kmeans.fit_predict(valid_embeddings)

    # ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ì— ë¼ë²¨ í• ë‹¹
    speaker_labels = ["UNKNOWN"] * len(segments)
    for idx, label in zip(valid_indices, labels):
        speaker_labels[idx] = f"SPEAKER_{label}"

    # ê° í™”ìë³„ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤
    speakers = {}
    for idx, label in zip(valid_indices, labels):
        speakers.setdefault(label, []).append(idx)

    print(f"\nğŸ¤ ìŒì„± ê¸°ë°˜ ì´ {n_speakers}ëª… í™”ì í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼:")
    for label, idxs in speakers.items():
        print(f"   SPEAKER_{label}: {len(idxs)}ê°œ ì„¸ê·¸ë¨¼íŠ¸")

    return speaker_labels, speakers

__all__ = ["analyze_voice_speakers"]
