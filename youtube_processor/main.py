# ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
import os  # ìš´ì˜ì²´ì œ ê²½ë¡œ ê´€ë ¨
import time  # ì‹œê°„ ì¸¡ì • ë° ëŒ€ê¸°
from pathlib import Path  # ê²½ë¡œ ê°ì²´í™”ë¥¼ ìœ„í•œ í‘œì¤€ ëª¨ë“ˆ
from pprint import pprint  # ë””ë²„ê¹…ìš© ë°ì´í„° ì´ì˜ê²Œ ì¶œë ¥
from typing import Optional
import glob

#ë‹¤ìš´ë¡œë“œ ê´€ë ¨(Youtube)
from downloader import download_audio, download_video # ìœ íŠœë¸Œ ì˜ìƒ ë° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ

#ì˜¤ë””ì˜¤ ì²˜ë¦¬/ë¶„ë¦¬
from demucs_wrapper import separate_vocals  # ë°°ê²½ìŒ/ìŒì„± ë¶„ë¦¬ (Demucs ì‚¬ìš©)
from pydub import AudioSegment  # mp3/wav ë³€í™˜ ë“± ì˜¤ë””ì˜¤ ì¡°ì‘
from speaker_diarization.split_mp3 import split_audio_by_token  # Token ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ ë‚˜ëˆ„ê¸°

#ìë§‰ ìƒì„± ë° ì²˜ë¦¬
from transcriber import transcribe_audio #, transcribe_audio_check  # Whisper ë“±ìœ¼ë¡œ ìë§‰ ìƒì„±
from level_up_textgrid import generate_sentence_json  # TextGrid ìë§‰ â†’ ë¬¸ì¥ JSON ë³€í™˜
from export_for_mfa import export_segments_for_mfa  # MFA í•™ìŠµìš© ìë§‰/ìŒì„± ë°ì´í„° í¬ë§·íŒ…
from format_segments_for_output import format_segments_for_output

#í™”ì ë¶„ì„/ë¶„ë¦¬
from speaker_diarization.who_is_speaker import analyze_speakers  # ì–¼êµ´ + ìë§‰ + ìŒì„± ê¸°ë°˜ í™”ì ì‹ë³„
from speaker_diarization.voice_analyzer import analyze_voice_speakers  # ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬ (e.g., pyannote)
from speaker_diarization.frame_extractor import extract_frames_per_segment  # ìë§‰ êµ¬ê°„ ê¸°ë°˜ í”„ë ˆì„ ì¶”ì¶œ
from speaker_diarization.split_segment import split_segments_by_half # í™”ìë¶„ë¦¬ í•¨ìˆ˜ 
from merge_words import merge_words_into_segments
#ìŒì„± í”¼ì¹˜ ë¶„ì„
from voice_to_pitch import create_pitch_json_with_token  # êµ¬ê°„ë³„ pitch(ìŒë†’ì´) ì¶”ì¶œ ë° ì €ì¥

#s3 ì—…ë¡œë“œ
from upload_file_to_s3 import upload_file_to_s3  # AWS S3 ì—…ë¡œë“œ


#ìœ í‹¸ í•¨ìˆ˜ ëª¨ìŒ
from utils import sanitize_filename, extract_video_id, reset_folder, run_mfa_align, generate_presigned_url   # ê²½ë¡œ ì •ë¦¬, ìœ íŠœë¸Œ ID ì¶”ì¶œ, í´ë” ì´ˆê¸°í™” ë“±

#í† í° ë° dbê´€ë ¨ ë¡œì§
from token_generator import create_token  # Token ìƒì„± (ìŒì„±+ìë§‰ ë¬¶ìŒ)

from sqlalchemy.orm import sessionmaker, Session  # DB ì„¸ì…˜ ê´€ë ¨
from postgres.models import Token, Script  # ORM ëª¨ë¸ ì •ì˜
from postgres.post_data import make_token  # Token + ë¬¸ì¥ â†’ DB ì €ì¥ í•¨ìˆ˜

from dotenv import load_dotenv
load_dotenv()
from postgres.database import engine  # SQLAlchemy DB ì—”ì§„

# ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬

# from pyannote.audio import Pipeline
# from collections import defaultdict # defaultdictê°€ ì—†ë‹¤ë©´ ì¶”ê°€
# from pyannote.audio.pipelines import SpeakerDiarization
from speaker_diarizer import diarize_main_speaker
import json # ë‹¤ìš´ë¡œë“œìš©

import torch
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# DB ì—”ì§„ì— ì—°ê²°ëœ ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„± (autocommit=False, autoflush=True ê¸°ë³¸ê°’ ì‚¬ìš©)
SessionLocal = sessionmaker(bind=engine)

# ì‹¤ì œ ì‚¬ìš©í•  DB ì„¸ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì´ê±¸ë¡œ ì¿¼ë¦¬ ìˆ˜í–‰)
db = SessionLocal()

def adjust_segment_boundaries_forward(segments):
    """
    ë¬¸ì¥ ì‚¬ì´ í…€ì„ ì• ë¬¸ì¥ì— ë¶™ì´ê¸°
    """
    if not segments:
        return segments
    
    adjusted_segments = []
    
    for i, seg in enumerate(segments):
        current_start = seg['start']
        current_end = seg['end']
        
        # ë‹¤ìŒ ë¬¸ì¥ê³¼ì˜ ê°„ê²©ì„ í˜„ì¬ ë¬¸ì¥ì— ë¶™ì´ê¸°
        if i < len(segments) - 1:
            next_start = segments[i+1]['start']
            gap = next_start - current_end
            if gap > 0:  # í…€ì´ ìˆìœ¼ë©´
                current_end += gap  # í˜„ì¬ ë¬¸ì¥ ëì„ ë’¤ë¡œ í™•ì¥
                print(f"[DEBUG] ë¬¸ì¥ {i+1}: í…€ {gap:.2f}ì´ˆë¥¼ ì• ë¬¸ì¥ì— ë¶™ì„ ({current_start:.2f}s - {current_end:.2f}s)")
        
        adjusted_segments.append({
            **seg,
            'start': current_start,
            'end': current_end
        })
    
    return adjusted_segments

def main_pipeline(youtube_url: str, movie_name: Optional[str] = None, actor_name: Optional[str] = None, start: Optional[float] = None, end: Optional[float] = None, n_speakers: Optional[int] = None, token_name: Optional[str] = None) -> Optional[list[int]]:
    try:
        print(f"[DEBUG] main_pipeline called with start={start}, end={end}")
        start_time = time.time()  # â±ï¸ ì‹œì‘ ì‹œê°„

        video_id = extract_video_id(youtube_url)
        video_filename = sanitize_filename(video_id)
        print({video_id})
        print({video_filename})
        mp4_path = os.path.join("downloads", video_filename + ".mp4")
        download_video(youtube_url, mp4_path)
        mp3_path, _ = download_audio(youtube_url, video_id, video_filename)
        
        # start~end êµ¬ê°„ë§Œ ì˜ë¦¬ê¸°
        if start is not None and end is not None:
            print(f"ğŸ”ª ì˜¤ë””ì˜¤ {start}~{end}ì´ˆ êµ¬ê°„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            audio = AudioSegment.from_file(mp3_path)
            trimmed = audio[int(start * 1000):int(end * 1000)]  # ms ë‹¨ìœ„
            trimmed_path = os.path.join("downloads", f"{video_filename}_trimmed_{start}_{end}.mp3")
            trimmed.export(trimmed_path, format="mp3")
            mp3_path = trimmed_path  # ì´í›„ ë¶„ë¦¬/ë¶„ì„ì— ì´ íŒŒì¼ ì‚¬ìš©
            print(f"âœ… ì˜ë¦° ì˜¤ë””ì˜¤ ì €ì¥: {trimmed_path}")

        if not os.path.exists(mp4_path):
            download_video(youtube_url, mp4_path)
        else:
            print(f"âœ… ì˜ìƒ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {mp4_path}")

        # 2-1  Demucsë¡œ ë³´ì»¬ ì¶”ì¶œ
        start_time = time.time()
        print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
        vocal_path = separate_vocals(mp3_path)
        elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
        print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

        start_time = time.time()
        print(f"ğŸ•’ ìë§‰ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
        segments = transcribe_audio(vocal_path)
        print("ğŸ—£ï¸ ì •ë°€ë¶„ì„:")
        for seg in segments:
            print(f"[{seg.get('start', 0):.1f}s - {seg.get('end', 0):.1f}s]: {seg.get('text', '')}")
        
        # ë¬¸ì¥ ê°„ í…€ì„ ì• ë¬¸ì¥ì— ë¶™ì´ê¸°
        print("ğŸ”§ ë¬¸ì¥ ê°„ í…€ì„ ì• ë¬¸ì¥ì— ë¶™ì´ëŠ” ì¤‘...")
        segments = adjust_segment_boundaries_forward(segments)
        print("ğŸ—£ï¸ í…€ ì¡°ì • í›„:")
        for seg in segments:
            print(f"[{seg.get('start', 0):.1f}s - {seg.get('end', 0):.1f}s]: {seg.get('text', '')}")
        
        selected = segments[:]

        if not segments:
            print("âŒ No speech detected.")
            return None

        word_list = format_segments_for_output(segments)

        # === í™”ì ìˆ˜ê°€ 1ëª…ì¼ ë•Œ: í™”ìë¶„ë¦¬/ì´ë¯¸ì§€ ì¶”ì¶œ ë“± ìŠ¤í‚µ ===
        if n_speakers == 1:
            print("ğŸ‘¤ í™”ì 1ëª…: í™”ìë¶„ë¦¬/ì´ë¯¸ì§€ ì¶”ì¶œ ë“± ìŠ¤í‚µ, ëª¨ë“  ë°ì´í„° S3/DB ì €ì¥")
            speaker_label = "SPEAKER_0"
            for seg in segments:
                seg['speaker'] = speaker_label
            post_word_data = merge_words_into_segments(segments, word_list)
            for seg in post_word_data:
                seg['speaker'] = speaker_label
            save_path = Path("cached_data/post_word_data.json")
            save_path.parent.mkdir(parents=True, exist_ok=True)
            with open(save_path, "w", encoding="utf-8") as f:
                json.dump(post_word_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… post_word_data ì €ì¥ ì™„ë£Œ: {save_path.resolve()}")
            # 1. TextGrid ìƒì„±
            export_segments_for_mfa(
                vocal_path=vocal_path,
                segments=segments,
                output_base="../syncdata/mfa/corpus",
                filename=video_filename,
                token_num=0
            )
            # 1.5. MFA align ì‹¤í–‰ (TextGrid ìƒì„±)
            run_mfa_align()
            textgrid_path = f"../syncdata/mfa/mfa_output/{video_filename}0.TextGrid"
            # 2. í”¼ì¹˜ ë°ì´í„° ìƒì„±
            print(f"[DEBUG] create_pitch_json_with_token í˜¸ì¶œ: vocal_path={vocal_path}, actor_name={actor_name}, pitch_path=./pitch_data/reference/{sanitize_filename(actor_name)}_{video_filename}_0pitch.json")
            create_pitch_json_with_token(
                vocal_path,
                {
                    "actor": actor_name,
                    "segments": post_word_data,
                    "speaker_label": speaker_label,
                    "video_url": youtube_url,  # ë°˜ë“œì‹œ í¬í•¨
                    "token_id": 0              # ë°˜ë“œì‹œ í¬í•¨
                }
            )
            pitch_path = f"./pitch_data/reference/{sanitize_filename(actor_name)}_{video_filename}_0pitch.json"
            print(f"[DEBUG] pitch_path: {pitch_path}, exists: {os.path.exists(pitch_path)}")
            # 3. S3 ì—…ë¡œë“œ
            bucket_name = "testgrid-pitch-bgvoice-yousync"
            s3_textgrid_url = upload_file_to_s3(textgrid_path, bucket_name, f"{actor_name}/{video_filename}/0/textgrid.TextGrid")
            s3_pitch_url = upload_file_to_s3(pitch_path, bucket_name, f"{actor_name}/{video_filename}/0/pitch.json")
            
            # ë³´ì»¬ ìŒì„± ì—…ë¡œë“œ
            print(f"[DEBUG] vocal_path: {vocal_path}, exists: {os.path.exists(vocal_path)}")
            s3_vocal_url = upload_file_to_s3(
                vocal_path,
                bucket_name,
                f"{actor_name}/{video_filename}/0/vocal.wav"
            )
            
            # bgvoice ê²½ë¡œë¥¼ ì‹¤ì œ ë¶„ë¦¬ëœ ì˜¤ë””ì˜¤ í´ë”ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            bgvoice_dir = Path(vocal_path).parent
            bgvoice_path = str(bgvoice_dir / "no_vocals.wav")
            print(f"[DEBUG] bgvoice_path: {bgvoice_path}, exists: {os.path.exists(bgvoice_path)}")
            s3_bgvoice_url = upload_file_to_s3(
                bgvoice_path,
                bucket_name,
                f"{actor_name}/{video_filename}/0/bgvoice.wav"
            )
            s3_textgrid_url = s3_textgrid_url or ""
            s3_pitch_url = s3_pitch_url or ""
            s3_vocal_url = s3_vocal_url or ""
            s3_bgvoice_url = s3_bgvoice_url or ""
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì • (start ì‹œê°„ ì¶”ê°€) - DB ì €ì¥ ì§ì „ì—ë§Œ
            if start is not None:
                print(f"[DEBUG] íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì •: ëª¨ë“  ì‹œê°„ì— +{start}ì´ˆ ì¶”ê°€")
                for seg in post_word_data:
                    seg['start'] += start
                    seg['end'] += start
                    if 'words' in seg:
                        for word in seg['words']:
                            word['start'] += start
                            word['end'] += start
            
            # 4. DB ì €ì¥
            token = make_token(
                db=db,
                movie_name=token_name or "",  # token_nameì„ movie_name ì¸ìë¡œ ì „ë‹¬
                actor_name=actor_name or "",
                speaker={
                    "actor": actor_name or "",
                    "segments": post_word_data,
                    "speaker_label": speaker_label,
                    "video_url": youtube_url,
                    "start_time": start,
                    "end_time": end,
                },
                audio_path=vocal_path,
                s3_textgrid_url=s3_textgrid_url,
                s3_pitch_url=s3_pitch_url,
                s3_bgvoice_url=s3_bgvoice_url,
            )
            if token is not None and hasattr(token, 'id'):
                print(f"âœ… DB ì €ì¥ ì™„ë£Œ, token id: {token.id}")
                try:
                    token_id = int(token.id)
                except Exception:
                    token_id = token.id
                if not isinstance(token_id, int):
                    return []
                return [token_id]
            return []

        # === ê¸°ì¡´ í™”ìë¶„ë¦¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ ===
        print("ğŸ‘¥ í™”ì 2ëª… ì´ìƒ: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
        print("ğŸ“¦ MFAìš© ìŒì„±/í…ìŠ¤íŠ¸ export:")
        print("ğŸ“¦ ì²«ë²ˆì§¸ MFAë¶„ì„ ëª©ì ì€ í™”ìë¶„ë¦¬ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° ìœ„í•¨ì´ë‹¤. ")
        print("â³ TextGrid ìƒì„± ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
        export_segments_for_mfa(
            vocal_path=vocal_path,
            segments=segments,
            output_base="../syncdata/mfa/corpus",
            filename=video_filename,
            token_num=0
        )
        start_time = time.time()
        print(f"ğŸ•’ ì¸¡ì •ì‹œì‘")
        run_mfa_align()
        elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
        print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

        speaker_diarization_data = generate_sentence_json(selected, f"../syncdata/mfa/mfa_output/{video_filename}0.TextGrid")
        for seg in speaker_diarization_data:
            seg["start"] = round(float(seg.get("start", 0)), 2)
            seg["end"] = round(float(seg.get("end", 0)), 2)
        for check in speaker_diarization_data:
            print(check)
        pprint(speaker_diarization_data)
        print("ì—¬ê¸° ì¶œë ¥ê°’ì€ ì •í™•íˆ í™”ìë¶„ë¦¬ë¥¼ ìœ„í•œ ë¬¸ì¥ íƒ€ì„ ìŠ¤í…œí”„ë¡œ í™œìš©ëœë‹¤.")

        extract_frames_per_segment(mp4_path, speaker_diarization_data, output_folder="tmp_frames")
        print("âœ… ì„¸ê·¸ë¨¼íŠ¸ë³„ í”„ë ˆì„ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ: tmp_frames/")

        from speaker_diarization.who_is_speaker import analyze_speakers_with_clustering, print_speaker_dialogue
        from speaker_diarization.voice_analyzer import analyze_voice_speakers_with_clustering
        face_labels, _ = analyze_speakers_with_clustering(
            len(speaker_diarization_data),
            folder="tmp_frames",
            n_speakers=2
        )
        n_speakers = 0
        # FastAPIì—ì„œëŠ” ì…ë ¥ ëŒ€ì‹  ê¸°ë³¸ê°’/ì¶”ë¡  ì‚¬ìš©
        n_speakers = len(set([l for l in face_labels if l != "UNKNOWN"]))
        if n_speakers < 1:
            n_speakers = 2
        voice_labels, _ = analyze_voice_speakers_with_clustering(
            vocal_path, speaker_diarization_data, n_speakers=n_speakers
        )
        final_labels = []
        for f, v in zip(face_labels, voice_labels):
            if f == v:
                final_labels.append(f)
            elif f == "UNKNOWN":
                final_labels.append(v)
            elif v == "UNKNOWN":
                final_labels.append(f)
            else:
                final_labels.append(v)  # ìŒì„± ìš°ì„ 
        for i, (seg, label) in enumerate(zip(speaker_diarization_data, final_labels)):
            seg['speaker'] = label
        print("\n=== ì–¼êµ´+ìŒì„± ìœµí•© í™”ìë¶„ë¦¬ ê²°ê³¼ ===")
        print_speaker_dialogue(speaker_diarization_data, final_labels)

        post_word_data = merge_words_into_segments(speaker_diarization_data, word_list)
        for seg in post_word_data:
            match = next(
                (s for s in speaker_diarization_data
                 if abs(s['start'] - seg['start']) < 0.01 and abs(s['end'] - seg['end']) < 0.01),
                None
            )
            if match and 'speaker' in match:
                seg['speaker'] = match['speaker']
            else:
                seg['speaker'] = 'UNKNOWN'

        save_path = Path("cached_data/post_word_data.json")
        save_path.parent.mkdir(parents=True, exist_ok=True)
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(post_word_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… post_word_data ì €ì¥ ì™„ë£Œ: {save_path.resolve()}")

        for seg in post_word_data:
            segment_start = seg.get("start", 0)
            segment_end = seg.get("end", 0)
            print(f'ğŸ“ {segment_start:.2f} ~ {segment_end:.2f}: {seg.get("text", "")}')
            if "words" in seg:
                for word in seg["words"]:
                    w_start = word.get("start", 0)
                    w_end = word.get("end", 0)
                    w_text = word.get("word", "")
                    print(f'    ğŸ”¹ {w_start:6.2f}s - {w_end:6.2f}s: {w_text}')

        HF_TOKEN = os.getenv("HF_TOKEN")
        with open(save_path, encoding="utf-8") as f:
            post_words = json.load(f)
        result = diarize_main_speaker(
            vocal_path     = vocal_path,
            post_word_data = post_words,
            hf_token       = HF_TOKEN or "",
        )
        main_speaker_label    = result["label"]
        main_speaker_segments = result["segments"]
        final_start_time      = result["start"]
        final_end_time        = result["end"]
        print("ğŸ‘‘ Main speaker:", main_speaker_label)
        for i, s in enumerate(main_speaker_segments, 1):
            print(f"[{i}] {s['start']:.2f}-{s['end']:.2f}: {s['text']}")

        from collections import defaultdict
        speaker_segments = defaultdict(list)
        for seg in post_word_data:
            speaker = seg['speaker']
            speaker_segments[speaker].append(seg)
        # actor_nameì´ ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ë™ì ìœ¼ë¡œ speaker_name_map ìƒì„±
        actor_names = [name.strip() for name in (actor_name or "").split(",") if name.strip()]
        speaker_name_map = {
            f"SPEAKER_{i}": actor_names[i] if i < len(actor_names) else f"SPEAKER_{i}"
            for i in range(len(actor_names))
        }
        speaker_name_map["UNKNOWN"] = "Unknown"
        speakers = []
        for speaker_label, segs in speaker_segments.items():
            segs = sorted(segs, key=lambda s: s['start'])
            start_time = segs[0]['start']
            end_time = segs[-1]['end']
            token_name = speaker_name_map.get(speaker_label, speaker_label)
            # token_idëŠ” SPEAKER_0, SPEAKER_1 ë“±ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
            if speaker_label.startswith("SPEAKER_") and speaker_label.split('_')[-1].isdigit():
                token_id = int(speaker_label.split('_')[-1])
            else:
                token_id = 0
            speakers.append({
                "actor": token_name,
                "video_url": youtube_url,
                "token_id": token_id,
                "speaker_label": speaker_label,
                "start_time": start_time,
                "end_time": end_time,
                "segments": segs
            })
        token_ids = []
        # ì „ì²´ íŠ¸ë¦¬ë° êµ¬ê°„ì˜ Demucs ë¶„ë¦¬ í´ë” ê²½ë¡œ (ì •ìˆ˜í˜•ìœ¼ë¡œ ë§ì¶¤)
        start_int = int(float(start)) if start is not None else 0
        end_int = int(float(end)) if end is not None else 0
        # Demucs ë¶„ë¦¬ í´ë”ëª…ì—ì„œ start, endë¥¼ ì œê±°í•˜ê³  video_filenameë§Œ ì‚¬ìš©
        # Demucs ë¶„ë¦¬ í´ë”ëª…ì€ í•­ìƒ ì…ë ¥ ì˜¤ë””ì˜¤ íŒŒì¼ëª…(stem)ê³¼ ë™ì¼í•˜ê²Œ ë§ì¶˜ë‹¤
        demucs_dir = f"separated/htdemucs/{Path(mp3_path).stem}"
        vocal_path = os.path.join(demucs_dir, "vocals.wav")
        bgvoice_path = os.path.join(demucs_dir, "no_vocals.wav")
        print(f"[DEBUG] demucs_dir: {demucs_dir}")
        print(f"[DEBUG] vocal_path: {vocal_path}")
        print(f"[DEBUG] bgvoice_path: {bgvoice_path}")
        for s3_data in speakers:
            actor = s3_data["actor"]
            # Demucs ë¶„ë¦¬ í´ë” ìë™ íƒìƒ‰
            vocal_glob = f"separated/htdemucs/{Path(mp3_path).stem}/vocals.wav"
            no_vocal_glob = f"separated/htdemucs/{Path(mp3_path).stem}/no_vocals.wav"
            vocal_matches = glob.glob(vocal_glob)
            no_vocal_matches = glob.glob(no_vocal_glob)
            if vocal_matches:
                vocal_path = vocal_matches[0]
            else:
                print(f"[ERROR] vocals.wav íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vocal_glob}")
                vocal_path = None
            if no_vocal_matches:
                bgvoice_path = no_vocal_matches[0]
            else:
                print(f"[ERROR] no_vocals.wav íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {no_vocal_glob}")
                bgvoice_path = None
            # í™”ìë³„ pitch ë¶„ì„ ë° pitch.json ê²½ë¡œ ìƒì„±
            pitch_path = f"./pitch_data/reference/{sanitize_filename(actor)}_{video_filename}_{s3_data['token_id']}pitch.json"
            print(f"[DEBUG] create_pitch_json_with_token (multi-speaker) í˜¸ì¶œ: vocal_path={vocal_path}, actor={actor}, pitch_path={pitch_path}")
            if vocal_path is not None:
                create_pitch_json_with_token(
                    vocal_path,
                    {
                        "actor": actor,
                        "segments": s3_data["segments"],
                        "speaker_label": s3_data["speaker_label"],
                        "video_url": youtube_url,
                        "token_id": s3_data["token_id"]
                    }
                )
            # split_audio_by_tokenì— ì „ì²´ êµ¬ê°„ íŒŒì¼ ê²½ë¡œ ì „ë‹¬
            if vocal_path is not None and bgvoice_path is not None and os.path.exists(vocal_path) and os.path.exists(bgvoice_path):
                split_audio_by_token([vocal_path, bgvoice_path], s3_data, video_filename)
            else:
                print(f"[ERROR] split_audio_by_tokenì— ë„˜ê¸¸ íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤: {vocal_path}, {bgvoice_path}")
            segments = s3_data["segments"]
            vocal_path_token = f"./split_tokens/vocals_{video_filename}_token_{s3_data['token_id']}.mp3"
            export_segments_for_mfa(
                vocal_path=vocal_path_token,
                segments=segments,
                output_base="../syncdata/mfa/corpus",
                filename=video_filename,
                token_num=s3_data["token_id"]
            )
        start_time = time.time()
        print("ğŸ•’ ì¸¡ì •ì‹œì‘")
        run_mfa_align()
        elapsed = time.time() - start_time
        print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        bucket_name = "testgrid-pitch-bgvoice-yousync"
        # 1. ë¶„ì„(MFCC, TextGrid, pitch ë“±)ì€ startë¥¼ ë”í•˜ì§€ ì•Šì€ ìƒíƒœ(0~êµ¬ê°„ê¸¸ì´)ë¡œ ì§„í–‰
        analysis_speakers = []
        for speaker in speakers:
            # deepcopyë¡œ ë¶„ì„ìš© ì„¸ê·¸ë¨¼íŠ¸ ë¶„ë¦¬ (startë¥¼ ë”í•˜ì§€ ì•Šì€ ìƒíƒœ)
            import copy
            analysis_speaker = copy.deepcopy(speaker)
            for seg in analysis_speaker["segments"]:
                # start, endì—ì„œ start ì˜¤í”„ì…‹ì„ ë¹¼ì„œ 0~êµ¬ê°„ê¸¸ì´ë¡œ ë§ì¶¤
                seg['start'] = float(seg['start']) - float(start or 0)
                seg['end'] = float(seg['end']) - float(start or 0)
                if 'words' in seg:
                    for word in seg['words']:
                        word['start'] = float(word['start']) - float(start or 0)
                        word['end'] = float(word['end']) - float(start or 0)
            analysis_speakers.append(analysis_speaker)
        # ì´í›„ ë¶„ì„(MFCC, pitch, TextGrid ë“±)ì€ analysis_speakers ì‚¬ìš©

        # 2. DB/S3 ì €ì¥ ì§ì „ì—ë§Œ startë¥¼ ë”í•´ì„œ ì›ë³¸ íƒ€ì„ìŠ¤íƒ¬í”„(33~55ì´ˆ ë“±)ë¡œ ë³€í™˜
        for s3_data in speakers:
            token_id = s3_data["token_id"]
            actor = s3_data["actor"]
            if start is not None:
                print(f"[DEBUG] í™”ì {token_id} íƒ€ì„ìŠ¤íƒ¬í”„ ì¡°ì •: ëª¨ë“  ì‹œê°„ì— +{start}ì´ˆ ì¶”ê°€ (DB/S3 ì €ì¥ìš©)")
                for seg in s3_data["segments"]:
                    seg['start'] = float(seg['start']) + float(start)
                    seg['end'] = float(seg['end']) + float(start)
                    if 'words' in seg:
                        for word in seg['words']:
                            word['start'] = float(word['start']) + float(start)
                            word['end'] = float(word['end']) + float(start)
            # ì´í›„ DB/S3 ì €ì¥ ì½”ë“œ (make_token ë“±) ê·¸ëŒ€ë¡œ ì§„í–‰
            # Demucs ë¶„ë¦¬ í´ë” ìë™ íƒìƒ‰ (mp3_path.stem ì‚¬ìš©)
            demucs_dir = f"separated/htdemucs/{Path(mp3_path).stem}"
            vocal_glob = f"{demucs_dir}/vocals.wav"
            no_vocal_glob = f"{demucs_dir}/no_vocals.wav"
            print(f"[DEBUG] vocal_glob: {vocal_glob}")
            print(f"[DEBUG] no_vocal_glob: {no_vocal_glob}")
            vocal_matches = glob.glob(vocal_glob)
            no_vocal_matches = glob.glob(no_vocal_glob)
            if vocal_matches:
                vocal_path = vocal_matches[0]
            else:
                print(f"[ERROR] vocals.wav íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {vocal_glob}")
                vocal_path = None
            if no_vocal_matches:
                bgvoice_path = no_vocal_matches[0]
            else:
                print(f"[ERROR] no_vocals.wav íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {no_vocal_glob}")
                bgvoice_path = None
            # ì´í›„ ì½”ë“œì—ì„œ vocal_path, bgvoice_path ì‚¬ìš©
            # S3/DB ì—…ë¡œë“œ ë³µêµ¬ ë° ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€
            s3_prefix = f"{actor}/{video_filename}/{token_id}"
            s3_textgird_key = f"{s3_prefix}/textgrid.TextGrid"
            s3_pitchdata_key = f"{s3_prefix}/pitch.json"
            s3_bgvoice_key = f"{s3_prefix}/bgvoice.wav"
            s3_textgrid_path = f"../syncdata/mfa/mfa_output/{video_filename}{token_id}.TextGrid"
            s3_pitchdata_path = f"./pitch_data/reference/{sanitize_filename(actor)}_{video_filename}_{token_id}pitch.json"
            s3_bgvoice_path = bgvoice_path
            s3_textgrid_url = s3_pitch_url = s3_bgvoice_url = None
            missing = False
            if not os.path.exists(s3_textgrid_path):
                print(f"[ERROR] TextGrid íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {s3_textgrid_path}")
                missing = True
            if not os.path.exists(s3_pitchdata_path):
                print(f"[ERROR] pitch.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {s3_pitchdata_path}")
                missing = True
            if not (s3_bgvoice_path and isinstance(s3_bgvoice_path, str) and os.path.exists(s3_bgvoice_path)):
                print(f"[ERROR] bgvoice.wav íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {s3_bgvoice_path}")
                missing = True
            if not (vocal_path and isinstance(vocal_path, str) and os.path.exists(vocal_path)):
                print(f"[ERROR] vocal.wav íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {vocal_path}")
                missing = True
            if missing:
                print(f"[SKIP] í™”ì {actor} (token_id={token_id})ì˜ S3/DB ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            try:
                s3_textgrid_url = upload_file_to_s3(s3_textgrid_path, bucket_name, s3_textgird_key)
                s3_pitch_url = upload_file_to_s3(s3_pitchdata_path, bucket_name, s3_pitchdata_key)
                s3_bgvoice_url = upload_file_to_s3(s3_bgvoice_path, bucket_name, s3_bgvoice_key)
            except FileNotFoundError as e:
                print(f"âŒ ë¡œì»¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
                continue
            except Exception as e:
                print(f"âŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
            if s3_textgrid_url and s3_pitch_url and s3_bgvoice_url and vocal_path is not None:
                token = make_token(
                    db=db,
                    movie_name=movie_name or "",
                    actor_name=actor,
                    speaker=s3_data,
                    audio_path=vocal_path,
                    s3_textgrid_url=s3_textgrid_url,
                    s3_pitch_url=s3_pitch_url,
                    s3_bgvoice_url=s3_bgvoice_url,
                )
                if token is not None and hasattr(token, 'id'):
                    print(f"âœ… DB ì €ì¥ ì™„ë£Œ, token id: {token.id}")
                    token_id_val = token.id
                    # Only append if token_id_val is a real int (not a SQLAlchemy Column object)
                    if isinstance(token_id_val, int):
                        token_ids.append(token_id_val)
                    else:
                        try:
                            # Some SQLAlchemy objects may be convertible to int, but skip if not
                            converted = int(token_id_val)
                            token_ids.append(converted)
                        except Exception:
                            print(f"[WARN] token.idê°€ intë¡œ ë³€í™˜ ë¶ˆê°€ ë˜ëŠ” Column ê°ì²´ì„: {token_id_val} (type={type(token_id_val)})")
        print(" TextGrid ê¸°ë°˜ í† í° ìƒì„± ì¤‘...")
        reset_folder("../syncdata/mfa/corpus", "../syncdata/mfa/mfa_output")
        reset_folder("tmp_frames", "downloads", "separated/htdemucs", "cached_data","pitch_data", "split_tokens")
        # ì‹¤ì œ DBì— ì €ì¥ëœ ì²« ë²ˆì§¸ í† í°ì˜ idë¥¼ ë°˜í™˜
        if token_ids:
            return token_ids  # ì—¬ëŸ¬ í™”ìì˜ token_id ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []
    except Exception as e:
        import traceback
        print("âŒ main_pipeline ë‚´ë¶€ ì˜ˆì™¸ ë°œìƒ:", e)
        traceback.print_exc()
        raise

# ê¸°ì¡´ main()ì€ FastAPI ë“±ì—ì„œ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ìƒëµí•˜ê±°ë‚˜, ì•„ë˜ì²˜ëŸ¼ ë‚¨ê²¨ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
if __name__ == "__main__":
    import traceback
    s_time = time.time()  # â±ï¸ ì‹œì‘ ì‹œê°„
    try:
        # ====== JSON íŒŒì¼ì—ì„œ ì—¬ëŸ¬ ê±´ ì²˜ë¦¬ (ë°ëª¨ìš©) ======
        try:
            with open("data.json", encoding="utf-8") as f:
                data = json.load(f)
            for item in data:
                url = item["url"]
                start = item["start"]
                end = item["end"]
                n_speakers = item["n_speakers"]
                token_name = item.get("token_name", "")

                if n_speakers == 1:
                    actor = item["actor"]
                    print(f"\n==== {actor} ({url}) {start}~{end}s, í™”ììˆ˜: {n_speakers} ====")
                    main_pipeline(url, actor_name=actor, start=start, end=end, n_speakers=n_speakers, token_name=token_name)
                elif n_speakers == 2:
                    actor1 = item["actor1"]
                    actor2 = item["actor2"]
                    print(f"\n==== {actor1}, {actor2} ({url}) {start}~{end}s, í™”ììˆ˜: {n_speakers} ====")
                    # ë‘ ëª…ì˜ ì´ë¦„ì„ ì½¤ë§ˆë¡œ ì—°ê²°í•´ì„œ ë„˜ê¹€
                    main_pipeline(
                        url,
                        actor_name=f"{actor1},{actor2}",
                        start=start,
                        end=end,
                        n_speakers=n_speakers,
                        token_name=token_name
                    )
                else:
                    print(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í™”ì ìˆ˜: {n_speakers}")
        except FileNotFoundError:
            print("data.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ì¡´ input() ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
            # youtube_url = input("ğŸ“º URL ì…ë ¥ì„ ë°”ëë‹ˆë‹¤.: ").strip()
            # main_pipeline(youtube_url)
    except Exception as e:
        print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
        traceback.print_exc()
    e_time = time.time() - s_time  # â±ï¸ ì†Œìš” ì‹œê°„
    print(f"ğŸ•’ ì „ì²´ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {e_time:.2f}ì´ˆ")