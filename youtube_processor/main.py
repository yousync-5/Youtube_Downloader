# ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
import os  # ìš´ì˜ì²´ì œ ê²½ë¡œ ê´€ë ¨
import time  # ì‹œê°„ ì¸¡ì • ë° ëŒ€ê¸°
from pathlib import Path  # ê²½ë¡œ ê°ì²´í™”ë¥¼ ìœ„í•œ í‘œì¤€ ëª¨ë“ˆ
from pprint import pprint  # ë””ë²„ê¹…ìš© ë°ì´í„° ì´ì˜ê²Œ ì¶œë ¥

#ë‹¤ìš´ë¡œë“œ ê´€ë ¨(Youtube)
from downloader import download_audio, download_video # ìœ íŠœë¸Œ ì˜ìƒ ë° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ

#ì˜¤ë””ì˜¤ ì²˜ë¦¬/ë¶„ë¦¬
from demucs_wrapper import separate_vocals  # ë°°ê²½ìŒ/ìŒì„± ë¶„ë¦¬ (Demucs ì‚¬ìš©)
from pydub import AudioSegment  # mp3/wav ë³€í™˜ ë“± ì˜¤ë””ì˜¤ ì¡°ì‘
from speaker_diarization.split_mp3 import split_audio_by_token  # Token ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ ë‚˜ëˆ„ê¸°

#ìë§‰ ìƒì„± ë° ì²˜ë¦¬
from transcriber import transcribe_audio #, transcribe_audio_check  # Whisper ë“±ìœ¼ë¡œ ìë§‰ ìƒì„±
from level_up_textgrid import generate_sentence_json  # TextGrid ìë§‰ â†’ ë¬¸ì¥ JSON ë³€í™˜
from export_for_mfa import export_segments_for_mfa  # MFA í•™ìŠµìš© ìë§‰/ìŒì„± ë°ì´í„° í¬ë§·íŒ…
from format_segments_for_output import format_segments_for_output

#í™”ì ë¶„ì„/ë¶„ë¦¬
from speaker_diarization.who_is_speaker import analyze_speakers  # ì–¼êµ´ + ìë§‰ + ìŒì„± ê¸°ë°˜ í™”ì ì‹ë³„
from speaker_diarization.voice_analyzer import analyze_voice_speakers  # ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬ (e.g., pyannote)
from speaker_diarization.frame_extractor import extract_frames_per_segment  # ìë§‰ êµ¬ê°„ ê¸°ë°˜ í”„ë ˆì„ ì¶”ì¶œ
from speaker_diarization.split_segment import split_segments_by_half # í™”ìë¶„ë¦¬ í•¨ìˆ˜ 
from merge_words import merge_words_into_segments
#ìŒì„± í”¼ì¹˜ ë¶„ì„
from voice_to_pitch import create_pitch_json_with_token  # êµ¬ê°„ë³„ pitch(ìŒë†’ì´) ì¶”ì¶œ ë° ì €ì¥

#s3 ì—…ë¡œë“œ
from upload_file_to_s3 import upload_file_to_s3  # AWS S3 ì—…ë¡œë“œ


#ìœ í‹¸ í•¨ìˆ˜ ëª¨ìŒ
from utils import sanitize_filename, extract_video_id, reset_folder, run_mfa_align, generate_presigned_url   # ê²½ë¡œ ì •ë¦¬, ìœ íŠœë¸Œ ID ì¶”ì¶œ, í´ë” ì´ˆê¸°í™” ë“±

#í† í° ë° dbê´€ë ¨ ë¡œì§
from token_generator import create_token  # Token ìƒì„± (ìŒì„±+ìë§‰ ë¬¶ìŒ)

from sqlalchemy.orm import sessionmaker, Session  # DB ì„¸ì…˜ ê´€ë ¨
from postgres.models import Token, Script  # ORM ëª¨ë¸ ì •ì˜
from postgres.post_data import make_token  # Token + ë¬¸ì¥ â†’ DB ì €ì¥ í•¨ìˆ˜

from dotenv import load_dotenv
load_dotenv()
from postgres.database import engine  # SQLAlchemy DB ì—”ì§„

# ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬

# from pyannote.audio import Pipeline
# from collections import defaultdict # defaultdictê°€ ì—†ë‹¤ë©´ ì¶”ê°€
# from pyannote.audio.pipelines import SpeakerDiarization
from speaker_diarizer import diarize_main_speaker
import json # ë‹¤ìš´ë¡œë“œìš©

import torch
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# DB ì—”ì§„ì— ì—°ê²°ëœ ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„± (autocommit=False, autoflush=True ê¸°ë³¸ê°’ ì‚¬ìš©)
SessionLocal = sessionmaker(bind=engine)

# ì‹¤ì œ ì‚¬ìš©í•  DB ì„¸ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì´ê±¸ë¡œ ì¿¼ë¦¬ ìˆ˜í–‰)
db = SessionLocal()

def main_pipeline(youtube_url, movie_name=None, actor_name=None):
    start_time = time.time()  # â±ï¸ ì‹œì‘ ì‹œê°„

    video_id = extract_video_id(youtube_url)
    video_filename = sanitize_filename(video_id)
    print({video_id})
    print({video_filename})
    mp4_path = os.path.join("downloads", video_filename + ".mp4")
    download_video(youtube_url, mp4_path)
    mp3_path, _ = download_audio(youtube_url, video_id, video_filename)

    if not os.path.exists(mp4_path):
        download_video(youtube_url, mp4_path)
    else:
        print(f"âœ… ì˜ìƒ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {mp4_path}")

    # 2-1  Demucsë¡œ ë³´ì»¬ ì¶”ì¶œ
    start_time = time.time()
    print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
    vocal_path = separate_vocals(mp3_path)
    elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
    print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

    start_time = time.time()
    print(f"ğŸ•’ ìë§‰ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
    segments = transcribe_audio(vocal_path)
    print("ğŸ—£ï¸ ì •ë°€ë¶„ì„:")
    for seg in segments:
        print(f"[{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}")
    selected = segments[:]

    if not segments:
        print("âŒ No speech detected.")
        return None

    word_list = format_segments_for_output(segments)

    print("ğŸ“¦ MFAìš© ìŒì„±/í…ìŠ¤íŠ¸ export:")
    print("ğŸ“¦ ì²«ë²ˆì§¸ MFAë¶„ì„ ëª©ì ì€ í™”ìë¶„ë¦¬ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° ìœ„í•¨ì´ë‹¤. ")
    print("â³ TextGrid ìƒì„± ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
    export_segments_for_mfa(
        vocal_path=vocal_path,
        segments=segments,
        output_base="../syncdata/mfa/corpus",
        filename=video_filename,
        token_num=0
    )
    start_time = time.time()
    print(f"ğŸ•’ ì¸¡ì •ì‹œì‘")
    run_mfa_align()
    elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
    print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

    speaker_diarization_data = generate_sentence_json(selected, f"../syncdata/mfa/mfa_output/{video_filename}0.TextGrid")
    for seg in speaker_diarization_data:
        seg["start"] = round(float(seg["start"]), 2)
        seg["end"] = round(float(seg["end"]), 2)
    for check in speaker_diarization_data:
        print(check)
    pprint(speaker_diarization_data)
    print("ì—¬ê¸° ì¶œë ¥ê°’ì€ ì •í™•íˆ í™”ìë¶„ë¦¬ë¥¼ ìœ„í•œ ë¬¸ì¥ íƒ€ì„ ìŠ¤í…œí”„ë¡œ í™œìš©ëœë‹¤.")

    extract_frames_per_segment(mp4_path, speaker_diarization_data, output_folder="tmp_frames")
    print("âœ… ì„¸ê·¸ë¨¼íŠ¸ë³„ í”„ë ˆì„ ì´ë¯¸ì§€ ì¶”ì¶œ ì™„ë£Œ: tmp_frames/")

    from speaker_diarization.who_is_speaker import analyze_speakers_with_clustering, print_speaker_dialogue
    from speaker_diarization.voice_analyzer import analyze_voice_speakers_with_clustering
    face_labels, _ = analyze_speakers_with_clustering(
        len(speaker_diarization_data),
        folder="tmp_frames",
        threshold=0.6
    )
    n_speakers = 0
    # FastAPIì—ì„œëŠ” ì…ë ¥ ëŒ€ì‹  ê¸°ë³¸ê°’/ì¶”ë¡  ì‚¬ìš©
    n_speakers = len(set([l for l in face_labels if l != "UNKNOWN"]))
    if n_speakers < 1:
        n_speakers = 2
    voice_labels, _ = analyze_voice_speakers_with_clustering(
        vocal_path, speaker_diarization_data, n_speakers=n_speakers
    )
    final_labels = []
    for f, v in zip(face_labels, voice_labels):
        if f == v:
            final_labels.append(f)
        elif f == "UNKNOWN":
            final_labels.append(v)
        elif v == "UNKNOWN":
            final_labels.append(f)
        else:
            final_labels.append(v)  # ìŒì„± ìš°ì„ 
    for i, (seg, label) in enumerate(zip(speaker_diarization_data, final_labels)):
        seg['speaker'] = label
    print("\n=== ì–¼êµ´+ìŒì„± ìœµí•© í™”ìë¶„ë¦¬ ê²°ê³¼ ===")
    print_speaker_dialogue(speaker_diarization_data, final_labels)

    post_word_data = merge_words_into_segments(speaker_diarization_data, word_list)
    for seg in post_word_data:
        match = next(
            (s for s in speaker_diarization_data
             if abs(s['start'] - seg['start']) < 0.01 and abs(s['end'] - seg['end']) < 0.01),
            None
        )
        if match and 'speaker' in match:
            seg['speaker'] = match['speaker']
        else:
            seg['speaker'] = 'UNKNOWN'

    save_path = Path("cached_data/post_word_data.json")
    save_path.parent.mkdir(parents=True, exist_ok=True)
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(post_word_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… post_word_data ì €ì¥ ì™„ë£Œ: {save_path.resolve()}")

    for seg in post_word_data:
        start = seg["start"]
        end = seg["end"]
        print(f'ğŸ“ {start:.2f} ~ {end:.2f}: {seg["text"]}')
        if "words" in seg:
            for word in seg["words"]:
                w_start = word["start"]
                w_end = word["end"]
                w_text = word["word"]
                print(f'    ğŸ”¹ {w_start:6.2f}s - {w_end:6.2f}s: {w_text}')

    HF_TOKEN = os.getenv("HF_TOKEN")
    with open(save_path, encoding="utf-8") as f:
        post_words = json.load(f)
    result = diarize_main_speaker(
        vocal_path     = vocal_path,
        post_word_data = post_words,
        hf_token       = HF_TOKEN,
    )
    main_speaker_label    = result["label"]
    main_speaker_segments = result["segments"]
    final_start_time      = result["start"]
    final_end_time        = result["end"]
    print("ğŸ‘‘ Main speaker:", main_speaker_label)
    for i, s in enumerate(main_speaker_segments, 1):
        print(f"[{i}] {s['start']:.2f}-{s['end']:.2f}: {s['text']}")

    from collections import defaultdict
    speaker_segments = defaultdict(list)
    for seg in post_word_data:
        speaker = seg['speaker']
        speaker_segments[speaker].append(seg)
    speaker_name_map = {
        "SPEAKER_0": "Natalie Portman",
        "SPEAKER_1": "Jude Law",
        "UNKNOWN": "Unknown"
    }
    speakers = []
    for idx, (speaker_label, segs) in enumerate(speaker_segments.items(), 1):
        segs = sorted(segs, key=lambda s: s['start'])
        start_time = segs[0]['start']
        end_time = segs[-1]['end']
        token_name = speaker_name_map.get(speaker_label, speaker_label)
        speakers.append({
            "actor": token_name,
            "video_url": youtube_url,
            "token_id": idx,
            "speaker_label": speaker_label,
            "start_time": start_time,
            "end_time": end_time,
            "segments": segs
        })
    token_ids = []
    for s3_data in speakers:
        vocal_path_obj = Path("separated") / "htdemucs" / video_filename / "vocals.wav"
        no_vocals_path_obj = Path("separated") / "htdemucs" / video_filename / "no_vocals.wav"
        split_audio_by_token([vocal_path_obj, no_vocals_path_obj], s3_data, video_filename)
        segments = s3_data["segments"]
        vocal_path_token = f"./split_tokens/vocals_{video_filename}_token_{s3_data['token_id']}.mp3"
        export_segments_for_mfa(
            vocal_path=vocal_path_token,
            segments=segments,
            output_base="../syncdata/mfa/corpus",
            filename=video_filename,
            token_num=s3_data["token_id"]
        )
    start_time = time.time()
    print("ğŸ•’ ì¸¡ì •ì‹œì‘")
    run_mfa_align()
    elapsed = time.time() - start_time
    print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    bucket_name = "testgrid-pitch-bgvoice-yousync"
    for s3_data in speakers:
        token_id = s3_data["token_id"]
        actor = s3_data["actor"]
        vocal_path = f"separated/htdemucs/{video_filename}/vocals.wav"  # ì „ì²´ ë³´ì»¬ ì˜¤ë””ì˜¤ ì‚¬ìš©
        bgvoice_path = f"./split_tokens/no_vocals_{video_filename}_token_{token_id}.mp3"
        create_pitch_json_with_token(vocal_path, s3_data)
        s3_prefix = f"{actor}/{video_filename}/{token_id}"
        s3_textgird_key = f"{s3_prefix}/textgrid.TextGrid"
        s3_pitchdata_key = f"{s3_prefix}/pitch.json"
        s3_bgvoice_key = f"{s3_prefix}/bgvoice.mp3"
        s3_textgrid_path = f"../syncdata/mfa/mfa_output/{video_filename}{token_id}.TextGrid"
        s3_pitchdata_path = f"./pitch_data/reference/{sanitize_filename(actor)}_{video_filename}_{token_id}pitch.json"
        s3_bgvoice_path = bgvoice_path
        try:
            s3_textgrid_url = upload_file_to_s3(s3_textgrid_path, bucket_name, s3_textgird_key)
            s3_pitch_url = upload_file_to_s3(s3_pitchdata_path, bucket_name, s3_pitchdata_key)
            s3_bgvoice_url = upload_file_to_s3(s3_bgvoice_path, bucket_name, s3_bgvoice_key)
        except FileNotFoundError as e:
            print(f"âŒ ë¡œì»¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
            continue
        except Exception as e:
            print(f"âŒ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue
        if s3_textgrid_url and s3_pitch_url and s3_bgvoice_url:
            token = make_token(
                db=db,
                movie_name=movie_name,
                actor_name=actor,
                speaker=s3_data,
                audio_path=vocal_path,
                s3_textgrid_url=s3_textgrid_url,
                s3_pitch_url=s3_pitch_url,
                s3_bgvoice_url=s3_bgvoice_url,
            )
            if token is not None and hasattr(token, 'id'):
                token_ids.append(token.id)
    print("ğŸ¯ TextGrid ê¸°ë°˜ í† í° ìƒì„± ì¤‘...")
    reset_folder("../syncdata/mfa/corpus", "../syncdata/mfa/mfa_output")
    reset_folder("tmp_frames", "downloads", "separated/htdemucs", "cached_data","pitch_data", "split_tokens")
    # ì‹¤ì œ DBì— ì €ì¥ëœ ì²« ë²ˆì§¸ í† í°ì˜ idë¥¼ ë°˜í™˜
    if token_ids:
        return token_ids  # ì—¬ëŸ¬ í™”ìì˜ token_id ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return []

# ê¸°ì¡´ main()ì€ FastAPI ë“±ì—ì„œ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ìƒëµí•˜ê±°ë‚˜, ì•„ë˜ì²˜ëŸ¼ ë‚¨ê²¨ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
if __name__ == "__main__":
    import traceback
    s_time = time.time()  # â±ï¸ ì‹œì‘ ì‹œê°„
    try:
        # main() ëŒ€ì‹  main_pipelineì„ ì§ì ‘ í˜¸ì¶œí•  ìˆ˜ ìˆìŒ
        youtube_url = input("ğŸ“º URL ì…ë ¥ì„ ë°”ëë‹ˆë‹¤.: ").strip()
        main_pipeline(youtube_url)
    except Exception as e:
        print("âŒ ì˜ˆì™¸ ë°œìƒ:", e)
        traceback.print_exc()
    e_time = time.time() - s_time  # â±ï¸ ì†Œìš” ì‹œê°„
    print(f"ğŸ•’ ì „ì²´ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {e_time:.2f}ì´ˆ")