# ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ
import os  # ìš´ì˜ì²´ì œ ê²½ë¡œ ê´€ë ¨
import time  # ì‹œê°„ ì¸¡ì • ë° ëŒ€ê¸°
from pathlib import Path  # ê²½ë¡œ ê°ì²´í™”ë¥¼ ìœ„í•œ í‘œì¤€ ëª¨ë“ˆ
from pprint import pprint  # ë””ë²„ê¹…ìš© ë°ì´í„° ì´ì˜ê²Œ ì¶œë ¥

#ë‹¤ìš´ë¡œë“œ ê´€ë ¨(Youtube)
from downloader import download_audio, download_video # ìœ íŠœë¸Œ ì˜ìƒ ë° ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ

#ì˜¤ë””ì˜¤ ì²˜ë¦¬/ë¶„ë¦¬
from demucs_wrapper import separate_vocals  # ë°°ê²½ìŒ/ìŒì„± ë¶„ë¦¬ (Demucs ì‚¬ìš©)
from pydub import AudioSegment  # mp3/wav ë³€í™˜ ë“± ì˜¤ë””ì˜¤ ì¡°ì‘
from speaker_diarization.split_mp3 import split_audio_by_token  # Token ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ ë‚˜ëˆ„ê¸°

#ìë§‰ ìƒì„± ë° ì²˜ë¦¬
from transcriber import transcribe_audio, transcribe_audio_check  # Whisper ë“±ìœ¼ë¡œ ìë§‰ ìƒì„±
from level_up_textgrid import generate_sentence_json  # TextGrid ìë§‰ â†’ ë¬¸ì¥ JSON ë³€í™˜
from export_for_mfa import export_segments_for_mfa  # MFA í•™ìŠµìš© ìë§‰/ìŒì„± ë°ì´í„° í¬ë§·íŒ…
from format_segments_for_output import format_segments_for_output

#í™”ì ë¶„ì„/ë¶„ë¦¬
from speaker_diarization.who_is_speaker import analyze_speakers  # ì–¼êµ´ + ìë§‰ + ìŒì„± ê¸°ë°˜ í™”ì ì‹ë³„
from speaker_diarization.voice_analyzer import analyze_voice_speakers  # ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬ (e.g., pyannote)
from speaker_diarization.frame_extractor import extract_frames_per_segment  # ìë§‰ êµ¬ê°„ ê¸°ë°˜ í”„ë ˆì„ ì¶”ì¶œ
from speaker_diarization.split_segment import split_segments_by_half # í™”ìë¶„ë¦¬ í•¨ìˆ˜ 
from merge_words import merge_words_into_segments
#ìŒì„± í”¼ì¹˜ ë¶„ì„
from voice_to_pitch import create_pitch_json_with_token  # êµ¬ê°„ë³„ pitch(ìŒë†’ì´) ì¶”ì¶œ ë° ì €ì¥

#s3 ì—…ë¡œë“œ
from upload_file_to_s3 import upload_file_to_s3  # AWS S3 ì—…ë¡œë“œ


#ìœ í‹¸ í•¨ìˆ˜ ëª¨ìŒ
from utils import sanitize_filename, extract_video_id, reset_folder, run_mfa_align, generate_presigned_url   # ê²½ë¡œ ì •ë¦¬, ìœ íŠœë¸Œ ID ì¶”ì¶œ, í´ë” ì´ˆê¸°í™” ë“±

#í† í° ë° dbê´€ë ¨ ë¡œì§
from token_generator import create_token  # Token ìƒì„± (ìŒì„±+ìë§‰ ë¬¶ìŒ)

from sqlalchemy.orm import sessionmaker, Session  # DB ì„¸ì…˜ ê´€ë ¨
from postgres.models import Token, Script  # ORM ëª¨ë¸ ì •ì˜
from postgres.post_data import make_token  # Token + ë¬¸ì¥ â†’ DB ì €ì¥ í•¨ìˆ˜

from dotenv import load_dotenv
load_dotenv()
from postgres.database import engine  # SQLAlchemy DB ì—”ì§„

# ìŒì„± ê¸°ë°˜ í™”ì ë¶„ë¦¬

# from pyannote.audio import Pipeline
# from collections import defaultdict # defaultdictê°€ ì—†ë‹¤ë©´ ì¶”ê°€
# from pyannote.audio.pipelines import SpeakerDiarization
from speaker_diarizer import diarize_main_speaker
import json # ë‹¤ìš´ë¡œë“œìš©

import torch
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# DB ì—”ì§„ì— ì—°ê²°ëœ ì„¸ì…˜ íŒ©í† ë¦¬ ìƒì„± (autocommit=False, autoflush=True ê¸°ë³¸ê°’ ì‚¬ìš©)
SessionLocal = sessionmaker(bind=engine)

# ì‹¤ì œ ì‚¬ìš©í•  DB ì„¸ì…˜ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì´ê±¸ë¡œ ì¿¼ë¦¬ ìˆ˜í–‰)
db = SessionLocal()

def main():

    # 1. ìœ íŠœë¸Œ ë°ì´í„° 

    # 1-1 URL ì €ì¥
    youtube_url = input("ğŸ“º URL ì…ë ¥ì„ ë°”ëë‹ˆë‹¤.: ").strip()


    #ë‹¹ì¥ì€ í•„ìš”ì¹˜ì•„ë‹ˆí•¨

    movie_name = None
    actor_name = None
    try:
        # í„°ë¯¸ë„ ì¸ì½”ë”© ì„¤ì •
        import sys
        if hasattr(sys.stdin, 'reconfigure'):
            sys.stdin.reconfigure(encoding='utf-8')
        
        movie_input = input("ì˜í™” ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")
        if movie_input and movie_input.strip():
            movie_name = movie_input.strip()
            
        actor_input = input("ë°°ìš° ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš” (ì„ íƒì‚¬í•­): ")
        if actor_input and actor_input.strip():
            actor_name = actor_input.strip()
            
    except (UnicodeDecodeError, UnicodeError) as e:
        print(f"ì…ë ¥ ì¸ì½”ë”© ì˜¤ë¥˜: {e}")
        print("ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        movie_name = None
        actor_name = None
    except Exception as e:
        print(f"ì…ë ¥ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        movie_name = None
        actor_name = None


    start_time = time.time()  # â±ï¸ ì‹œì‘ ì‹œê°„

    # 1-2 ë¹„ë””ì˜¤ ID/FileName ì¶”ì¶œ
    video_id = extract_video_id(youtube_url)
    video_filename = sanitize_filename(video_id)
    print({video_id})
    print({video_filename})
    # 1-3 í´ë” ê²½ë¡œì§€ì •
    mp4_path = os.path.join("downloads", video_filename + ".mp4")
    download_video(youtube_url, mp4_path)
    # 1-4 ì˜¤ë””ì˜¤ ì¶”ì¶œ ë° íŒŒì¼ ê²½ë¡œ ë°˜í™˜ 
    mp3_path, _ = download_audio(youtube_url, video_id, video_filename)
 
    # 1-5 ì˜ìƒì´ ì—†ì„ ì‹œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
    if not os.path.exists(mp4_path):
        download_video(youtube_url, mp4_path)
    else:
        print(f"âœ… ì˜ìƒ íŒŒì¼ ì´ë¯¸ ì¡´ì¬: {mp4_path}")

    # 2. ë°ì´í„° ì¶”ì¶œ

    # 2-1  Demucsë¡œ ë³´ì»¬ ì¶”ì¶œ
    
    start_time = time.time()
    print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
    vocal_path = separate_vocals(mp3_path)
    
    elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
    print(f"ğŸ•’ ë³´ì»¬ ì¶”ì¶œ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")


    start_time = time.time()
    print(f"ğŸ•’ ìë§‰ ì¶”ì¶œ ì¸¡ì •ì‹œì‘")
    # 2-2  Whisperë¡œ ìë§‰ ì¶”ì¶œ
    segments = transcribe_audio(vocal_path)
    print("ğŸ—£ï¸ ì •ë°€ë¶„ì„:")
    for seg in segments:
        print(f"[{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}")
    selected = segments[:]

    if not segments:
        print("âŒ No speech detected.")
        return

    # elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
    # print(f"ğŸ•’ ìë§‰ ì¶”ì¶œ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")


    check_segment = transcribe_audio_check(vocal_path)


    print("ğŸ—£ï¸ First 5 segments:")
    for seg in check_segment:
        print(f"[{seg['start']:.1f}s - {seg['end']:.1f}s]: {seg['text']}")


    #ì˜ˆì™¸ì²˜ë¦¬



    # í…ŒìŠ¤íŠ¸ìš©
    word_list = format_segments_for_output(segments)
    # print("ğŸ—£ï¸ ì„ íƒëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸:")
    # for i, seg in enumerate(word_list, 1):
    #     print(f"{i:>2}. â±ï¸ {seg['start']:.2f}s ~ {seg['end']:.2f}s | ğŸ“ "{seg['text']}"")

    #     if "words" in seg:
    #         for w in seg["words"]:
    #             w_start = round(w["start"], 2)
    #             w_end = round(w["end"], 2)
    #             w_text = w["word"].strip()
    #             print(f"    ğŸ”¹ {w_start:.2f}s - {w_end:.2f}s: {w_text}")

    

    # ğŸ”¡ MFAìš© ì„¸ê·¸ë¨¼íŠ¸ ë‚´ë³´ë‚´ê¸°
    print("ğŸ“¦ MFAìš© ìŒì„±/í…ìŠ¤íŠ¸ export:")


    print("ğŸ“¦ ì²«ë²ˆì§¸ MFAë¶„ì„ ëª©ì ì€ í™”ìë¶„ë¦¬ ë°ì´í„°ë¥¼ ë§Œë“¤ê¸° ìœ„í•¨ì´ë‹¤. ")
    print("â³ TextGrid ìƒì„± ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
  
    export_segments_for_mfa(
        vocal_path=vocal_path,
        segments=segments,
        output_base="../syncdata/mfa/corpus",
        filename=video_filename,
        token_num=0
    )  
    start_time = time.time()
    print(f"ğŸ•’ ì¸¡ì •ì‹œì‘")
    
    # MFA ì²˜ë¦¬ë¥¼ try-exceptë¡œ ê°ì‹¸ì„œ ì˜¤ë¥˜ ì‹œì—ë„ ê³„ì† ì§„í–‰
    try:
        run_mfa_align()
        elapsed = time.time() - start_time  # â±ï¸ ì†Œìš” ì‹œê°„
        print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        
        # MFA ê²°ê³¼ë¥¼ ì‚¬ìš©í•œ í™”ì ë¶„ë¦¬ ë°ì´í„° ìƒì„±
        speaker_diarization_data = generate_sentence_json(selected,f"../syncdata/mfa/mfa_output/{video_filename}0.TextGrid" )
        print("âœ… MFA ê¸°ë°˜ í™”ì ë¶„ë¦¬ ë°ì´í„° ìƒì„± ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ MFA ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ”„ MFA ì—†ì´ ê¸°ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
        # MFA ì—†ì´ ê¸°ë³¸ segments ë°ì´í„° ì‚¬ìš©
        speaker_diarization_data = []
        for i, seg in enumerate(segments):
            speaker_diarization_data.append({
                "start": round(seg["start"], 2),
                "end": round(seg["end"], 2), 
                "text": seg["text"],
                "speaker": f"SPEAKER_{i % 2}"  # ì„ì‹œë¡œ 2ëª…ì˜ í™”ìë¡œ ë¶„í• 
            })
        print("âœ… ê¸°ë³¸ í™”ì ë¶„ë¦¬ ë°ì´í„° ìƒì„± ì™„ë£Œ")

    for seg in speaker_diarization_data:
        seg["start"] = round(float(seg["start"]), 2)
        seg["end"] = round(float(seg["end"]), 2)
    for check in speaker_diarization_data:
        print(check)
    pprint(speaker_diarization_data)

    print("ì—¬ê¸° ì¶œë ¥ê°’ì€ ì •í™•íˆ í™”ìë¶„ë¦¬ë¥¼ ìœ„í•œ ë¬¸ì¥ íƒ€ì„ ìŠ¤í…œí”„ë¡œ í™œìš©ëœë‹¤.")

    post_word_data = merge_words_into_segments(speaker_diarization_data, word_list)

    #####################################################
    ## testë¥¼ ìœ„í•œ ì €ì¥
    save_path = Path("cached_data/post_word_data.json")
    save_path.parent.mkdir(parents=True, exist_ok=True)  # í´ë” ì—†ìœ¼ë©´ ìƒì„±

    # JSON ì €ì¥
    with open(save_path, "w", encoding="utf-8") as f:
        json.dump(post_word_data, f, ensure_ascii=False, indent=2)

    print(f"âœ… post_word_data ì €ì¥ ì™„ë£Œ: {save_path.resolve()}")
    #####################################################


    print("ì´ë²ˆì—ëŠ” ê¸°ëŒ€ë¥¼ í•´ë´…ë‹ˆë‹¤.")

    for seg in post_word_data:
        start = seg["start"]
        end = seg["end"]
        print(f'ğŸ“ {start:.2f} ~ {end:.2f}: {seg["text"]}')
        
        if "words" in seg:
            for word in seg["words"]:
                w_start = word["start"]
                w_end = word["end"]
                w_text = word["word"]
                print(f'    ğŸ”¹ {w_start:6.2f}s - {w_end:6.2f}s: {w_text}')

    # for seg in result:
    #     print(f"ğŸŸ¢ {seg['start']}s - {seg['end']}s: {seg['text']}")
    #     if "words" in seg:
    #         for w in seg["words"]:
    #             print(f"   ğŸ”¹ {w['start']}s - {w['end']}s: {w['text']}")


    # print("â³ ì´ ì‹œì ì—ì„œ ë½‘í˜€ì§„ textgridì™€ segmentë¡œ í™”ìë¥¼ ë¶„ë¦¬ ë°ì´í„°ë¥¼ ë§Œë“  í›„ í´ë”ë¥¼ ë¹„ìš°ê³  í™”ìë³„ë¡œ ì¬ìš”ì²­ì„ ë³´ë‚´ì•¼í•œë‹¤")


    #ê°ì²´ ë°°ì—´ì´ ë°˜í™˜ëœë‹¤. ë°°ì—´ì˜ ë‚´ìš©ì€ 
    #í™”ìë¶„ë¦¬ ë¡œì§ ìœ„ì¹˜
    #í™”ì ë¶„ë¦¬ ë°ì´í„°ê°€ ë‚˜ì˜¨ë‹¤ë©´ ì˜¤ë””ì˜¤ë„ ê¸°ì¤€ì— ë§ì¶° ì˜ë¼ì ¸ì•¼í•œë‹¤. 
 

    # print("ë§Œì•½ ì´ë ‡ê²Œ ë¶„í• ì— ì„±ê³µí•œë‹¤ë©´ ì§€ê¸ˆ ì¦‰ì‹œ syncdata íŒŒì¼ ë‚´ì˜ ë°ì´í„°ë“¤ì€ ì§€ìš°ê³  ìƒˆë¡œ ìš”ì²­ì„ ë°•ì.")


    #í™”ìë¶„ë¦¬ ë°ì´í„°ê°€ ë½‘í˜€ì•¼í•œë‹¤. 
########################################################################################

    HF_TOKEN = os.getenv("HF_TOKEN")
    # VOCAL_MP3  = f"split_tokens/vocals_{video_filename}_token_1.mp3"
    # POST_JSON  = "cached_data/post_word_data.json"

    with open(save_path, encoding="utf-8") as f:
    # with open(POST_JSON, encoding="utf-8") as f:
        post_words = json.load(f)

    result = diarize_main_speaker(
        vocal_path     = vocal_path,
        post_word_data = post_words,
        hf_token       = HF_TOKEN,
    )
    # diar_result êµ¬ì¡°:  {'label', 'segments', 'start', 'end'}
    main_speaker_label    = result["label"]
    main_speaker_segments = result["segments"]
    final_start_time      = result["start"]
    final_end_time        = result["end"]


    print("ğŸ‘‘ Main speaker:", main_speaker_label)
    for i, s in enumerate(main_speaker_segments, 1):
        print(f"[{i}] {s['start']:.2f}-{s['end']:.2f}: {s['text']}")

    speakers = [
        {
            "actor": actor_name,    # ìŠ¤í¬ë¦½íŠ¸ ì´ˆê¸°ì— ì…ë ¥ë°›ì€ ë°°ìš° ì´ë¦„
            "video_url": youtube_url,
            "token_id": 1,          # ì£¼ìš” í™”ìëŠ” í•­ìƒ token_id 1ì„ ê°€ì§
            "speaker_label": main_speaker_label,
            "start_time": final_start_time,
            "end_time": final_end_time,
            "segments": main_speaker_segments
        }
    ]
    # ==================

    # print("í•´ë‹¹ì§€ì ì—ì„œ í™”ìë¶„ë¦¬í•˜ë‹¤ê°€ í„°ì§„ë‹¤/n")
    # speaker = post_word_data
    # split_segments_by_half(post_word_data, youtube_url,actor_name)
    
    
    #S3 ì±„ìš°ê¸° + í™”ìë¶„ë¦¬ ë°ì´í„° ë¶„í• ë¡œì§

    vocal_path = Path("separated") / "htdemucs" /video_filename / "vocals.wav"
    no_vocals_path =  Path("separated") / "htdemucs" /video_filename / "no_vocals.wav"
    
    # ì¶”ê°€#
    for speaker in speakers:
        split_audio_by_token([vocal_path, no_vocals_path], speaker, video_filename)


    #ìƒˆë¡œìš´ textê·¸
    reset_folder("../syncdata/mfa/corpus", "../syncdata/mfa/mfa_output")
    print("ì œê±°ì„±ê³µ")
    # 1. ë¨¼ì € ëª¨ë“  tokenì— ëŒ€í•´ lab/wav exportë§Œ ìˆ˜í–‰
    for s3_data in speakers:
        print(f"â–¶ï¸ ì²˜ë¦¬ ì¤‘: token_id={s3_data['token_id']}")
        
        segments = s3_data["segments"]
        vocal_path = f"./split_tokens/vocals_{video_filename}_token_{s3_data['token_id']}.mp3"
        export_segments_for_mfa(
            vocal_path=vocal_path,
            segments=segments,
            output_base="../syncdata/mfa/corpus",
            filename=video_filename,
            token_num=s3_data["token_id"]
        )

    # 2. MFA ì‹¤í–‰ì€ í•œ ë²ˆë§Œ
    start_time = time.time()
    print("ğŸ•’ ì¸¡ì •ì‹œì‘")
    try:
        run_mfa_align()
        elapsed = time.time() - start_time
        print(f"ğŸ•’ ì „ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print("âœ… MFA ì²˜ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ MFA ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ”„ MFA ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")

    bucket_name = "testgrid-pitch-bgvoice-yousync"
    # 3. ì´í›„ pitch, ì—…ë¡œë“œ, DB ì €ì¥ ì²˜ë¦¬ ë°˜ë³µ
    for s3_data in speakers:
        token_id = s3_data["token_id"]
        actor = s3_data.get("actor", "unknown")  # ì•ˆì „í•˜ê²Œ actor ê°’ ê°€ì ¸ì˜¤ê¸°, ì—†ìœ¼ë©´ "unknown" ì‚¬ìš©
        
        # actorê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
        if not actor or actor.strip() == "":
            actor = "unknown_actor"
        
        print(f"ğŸ” ì²˜ë¦¬ ì¤‘ì¸ í† í° ì •ë³´:")
        print(f"  - token_id: {token_id}")
        print(f"  - actor: '{actor}' (type: {type(actor)})")
        print(f"  - s3_data keys: {list(s3_data.keys())}")

        vocal_path = f"./split_tokens/vocals_{video_filename}_token_{token_id}.mp3"
        bgvoice_path = f"./split_tokens/no_vocals_{video_filename}_token_{token_id}.mp3"

        # pitch ì¶”ì¶œ
        create_pitch_json_with_token(vocal_path, s3_data)

        # S3 ê²½ë¡œ êµ¬ì„±
        s3_prefix = f"{actor}/{video_filename}/{token_id}"
        s3_textgird_key = f"{s3_prefix}/textgrid.TextGrid"
        s3_pitchdata_key = f"{s3_prefix}/pitch.json"
        s3_bgvoice_key = f"{s3_prefix}/bgvoice.mp3"
        
        s3_textgrid_path = f"../syncdata/mfa/mfa_output/{video_filename}{token_id}.TextGrid"
        s3_pitchdata_path = f"./pitch_data/reference/{sanitize_filename(actor)}_{video_filename}_{token_id}pitch.json"
        s3_bgvoice_path = bgvoice_path

        # S3 ì—…ë¡œë“œ ë³€ìˆ˜ ì´ˆê¸°í™”
        s3_textgrid_url = None
        s3_pitch_url = None
        s3_bgvoice_url = None
        
        # S3 ì—…ë¡œë“œ
        try:
            s3_textgrid_url = upload_file_to_s3(s3_textgrid_path, bucket_name, s3_textgird_key)
            print(f"âœ… TextGrid S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_textgrid_url}")
        except FileNotFoundError as e:
            print(f"âŒ TextGrid íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
        except Exception as e:
            print(f"âŒ TextGrid S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        try:
            s3_pitch_url = upload_file_to_s3(s3_pitchdata_path, bucket_name, s3_pitchdata_key)
            print(f"âœ… Pitch ë°ì´í„° S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_pitch_url}")
        except FileNotFoundError as e:
            print(f"âŒ Pitch íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
        except Exception as e:
            print(f"âŒ Pitch S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            
        try:
            s3_bgvoice_url = upload_file_to_s3(s3_bgvoice_path, bucket_name, s3_bgvoice_key)
            print(f"âœ… ë°°ê²½ìŒì„± S3 ì—…ë¡œë“œ ì„±ê³µ: {s3_bgvoice_url}")
        except FileNotFoundError as e:
            print(f"âŒ ë°°ê²½ìŒì„± íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e.filename}")
        except Exception as e:
            print(f"âŒ ë°°ê²½ìŒì„± S3 ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

        # DB ì €ì¥ (ë°°ê²½ìŒì„±ì´ ìˆìœ¼ë©´ ì €ì¥, í”¼ì¹˜ ë°ì´í„°ëŠ” ì„ íƒì‚¬í•­)
        print(f"ğŸ” S3 ì—…ë¡œë“œ ê²°ê³¼ í™•ì¸:")
        print(f"  - TextGrid URL: {s3_textgrid_url}")
        print(f"  - Pitch URL: {s3_pitch_url}")
        print(f"  - ë°°ê²½ìŒì„± URL: {s3_bgvoice_url}")
        
        if s3_bgvoice_url:  # ë°°ê²½ìŒì„±ë§Œ ìˆì–´ë„ ì €ì¥
            print("ğŸ¯ ë°ì´í„°ë² ì´ìŠ¤ì— í† í° ì €ì¥ ì¤‘...")
            try:
                result = make_token(
                    db=db,
                    movie_name = movie_name,
                    actor_name=actor,
                    speaker=s3_data,
                    s3_textgrid_url=s3_textgrid_url if s3_textgrid_url else "",
                    s3_pitch_url=s3_pitch_url if s3_pitch_url else "",
                    s3_bgvoice_url=s3_bgvoice_url,
                )
                if result:
                    print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì„±ê³µ: Token ID={result.id}")
                else:
                    print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨")
            except Exception as e:
                print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
        else:
            print("âŒ ë°°ê²½ìŒì„± íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            print("   í•„ìš”í•œ íŒŒì¼ë“¤:")
            print(f"   - TextGrid: {s3_textgrid_path} ({'ì¡´ì¬' if os.path.exists(s3_textgrid_path) else 'ì—†ìŒ'})")
            print(f"   - Pitch: {s3_pitchdata_path} ({'ì¡´ì¬' if os.path.exists(s3_pitchdata_path) else 'ì—†ìŒ'})")
            print(f"   - ë°°ê²½ìŒì„±: {s3_bgvoice_path} ({'ì¡´ì¬' if os.path.exists(s3_bgvoice_path) else 'ì—†ìŒ'})")

    print("ğŸ¯ TextGrid ê¸°ë°˜ í† í° ìƒì„± ì¤‘...")


    # audio = AudioSegment.from_file(no_vocals_path, format="mp3")


    # amplified = audio + 6 
    # amplified.export("amplified_output.mp3", format="mp3")

    # amplified.export(no_vocals_path,format ='mp3')



    reset_folder("../syncdata/mfa/corpus", "../syncdata/mfa/mfa_output")
    reset_folder("tmp_frames", "downloads", "separated/htdemucs", "pitch_data", "split_tokens")

# ì‹¤í–‰
if __name__ == "__main__":
    main()