import whisper_timestamped as wts
import json

def validate_and_fix_timestamps(words):
    fixed_words = []
    prev_end = 0.0

    for w in words:
        start = float(w.get('start', 0.0))
        end = float(w.get('end', 0.0))
        word = w.get('text') or w.get('word', '')

        if start >= end:
            print(f"âš ï¸ ë¬´íš¨ ë‹¨ì–´ íƒ€ìž„ìŠ¤íƒ¬í”„ (start >= end): {word}")
            continue

        if start < prev_end:
            if end <= prev_end:
                print(f"âš ï¸ {word} ë‹¨ì–´ ì‹œê°„ ì „ì²´ê°€ ì´ì „ê³¼ ê²¹ì¹¨ â†’ ë¬´ì‹œ")
                continue
            else:
                # ê²¹ì¹˜ëŠ” ë¶€ë¶„ë§Œ ë°€ê¸°
                print(f"âš ï¸ {word} ë‹¨ì–´ start ë³´ì •: {start:.2f} â†’ {prev_end:.2f}")
                start = prev_end

        fixed_words.append({
            'word': word,
            'start': start,
            'end': end
        })

        prev_end = max(prev_end, end)

    return fixed_words


def transcribe_audio(vocals_path):
    print("ðŸŽ™ï¸ìžë§‰ì¶”ì¶œ ê¸°ë³¸ ëª¨ë¸ í˜¸ì¶œ ")
    model = wts.load_model("base")

    print("ðŸ§  ìŒì„± ë°ì´í„° í…ìŠ¤íŠ¸ ë³€í™˜ì¤‘...")
    result = model.transcribe(
        vocals_path,
        word_timestamps=True,
        temperature=0.0,                             # ë¬´ìž‘ìœ„ì„± ì œê±°
        best_of=3,                                   # í›„ë³´ ì¤‘ 1ê°œë§Œ ê³ ë ¤
        beam_size=3,                                 # Beam search ë¹„í™œì„±í™” (greedy decoding)
        compression_ratio_threshold=float('inf'),    # ê¸¸ì´ ì œí•œ ì—†ìŒ (ì§¤ë¦¬ëŠ” ê²ƒ ë°©ì§€)
        logprob_threshold= -5,             # í™•ë¥  ê¸°ì¤€ ë¹„í™œì„±í™”
        no_speech_threshold=0.5                       # ë¬´ìŒ ì œê±° ê¸°ì¤€ ë¹„í™œì„±í™”
    )

    segments = result.get("segments", [])
    print(f"ðŸ“ ì´ {len(segments)} ê°œì˜ ë¬¸ìž¥ ì¶”ì¶œ.")

    # ê° segment ë‚´ ë‹¨ì–´ íƒ€ìž„ìŠ¤íƒ¬í”„ ê²€ì‚¬ ë° ë³´ì •
    for seg in segments:
        words = seg.get('words', [])
        fixed_words = validate_and_fix_timestamps(words)
        seg['words'] = fixed_words

    return segments

def transcribe_audio_check(vocals_path):
    print("ðŸŽ™ï¸ìžë§‰ì¶”ì¶œ ê¸°ë³¸ ëª¨ë¸ í˜¸ì¶œ ")
    model = wts.load_model("base")

    print("ðŸ§  ìŒì„± ë°ì´í„° í…ìŠ¤íŠ¸ ë³€í™˜ì¤‘...")
    result = model.transcribe(vocals_path, word_timestamps=True)

    segments = result.get("segments", [])
    print(f"ðŸ“ ì´ {len(segments)} ê°œì˜ ë¬¸ìž¥ ì¶”ì¶œ.")
    return segments