import whisper_timestamped as wts
import json
import torch

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")                  # cuda:0 ì—¬ì•¼ í•©ë‹ˆë‹¤

def validate_and_fix_timestamps(words):
    fixed_words = []
    prev_end = 0.0

    for w in words:
        start = float(w.get('start', 0.0))
        end = float(w.get('end', 0.0))
        word = w.get('text') or w.get('word', '')

        if start >= end:
            print(f"âš ï¸ ë¬´íš¨ ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ (start >= end): {word}")
            continue

        if start < prev_end:
            if end <= prev_end:
                print(f"âš ï¸ {word} ë‹¨ì–´ ì‹œê°„ ì „ì²´ê°€ ì´ì „ê³¼ ê²¹ì¹¨ â†’ ë¬´ì‹œ")
                continue
            else:
                # ê²¹ì¹˜ëŠ” ë¶€ë¶„ë§Œ ë°€ê¸°
                print(f"âš ï¸ {word} ë‹¨ì–´ start ë³´ì •: {start:.2f} â†’ {prev_end:.2f}")
                start = prev_end

        fixed_words.append({
            'word': word,
            'start': start,
            'end': end
        })

        prev_end = max(prev_end, end)

    return fixed_words


def split_long_segment(seg,
                       max_len=8.0,
                       pause_thresh=0.3):
    """
    í•˜ë‚˜ì˜ seg(ë¬¸ì¥ ë©ì–´ë¦¬)ê°€ ë„ˆë¬´ ê¸¸ë©´
    ë‹¨ì–´ ê°„ ë¬´ìŒ(pause) ê¸°ì¤€ìœ¼ë¡œ ì˜ê²Œ ë‚˜ëˆ ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
    """
    if (seg["end"] - seg["start"]) < max_len or "words" not in seg:
        return [seg]

    results, cur = [], {"start": seg["start"], "words": []}
    prev_end = seg["start"]

    for w in seg["words"]:
        pause = w["start"] - prev_end
        if pause > pause_thresh and cur["words"]:
            # ìƒˆ ì¡°ê° ì™„ë£Œ
            cur["end"]  = prev_end
            cur["text"] = " ".join(t["word"] for t in cur["words"])
            results.append(cur)
            # ë‹¤ìŒ ì¡°ê° ì‹œì‘
            cur = {"start": w["start"], "words": []}

        cur["words"].append(w)
        prev_end = w["end"]

    # ë§ˆì§€ë§‰ ì¡°ê°
    if cur["words"]:
        cur["end"]  = prev_end
        cur["text"] = " ".join(t["word"] for t in cur["words"])
        results.append(cur)

    return results


def transcribe_audio(vocals_path):
    print("ğŸ™ï¸ìë§‰ì¶”ì¶œ ê¸°ë³¸ ëª¨ë¸ í˜¸ì¶œ ")
    model = wts.load_model("base").to(device)

    print("ğŸ§  ìŒì„± ë°ì´í„° í…ìŠ¤íŠ¸ ë³€í™˜ì¤‘...")
    # result = model.transcribe(
    #     vocals_path,
    #     word_timestamps=True,
    #     language="en",
    #     temperature=0.0,                             # ë¬´ì‘ìœ„ì„± ì œê±°
    #     best_of=3,                                   # í›„ë³´ ì¤‘ 1ê°œë§Œ ê³ ë ¤
    #     beam_size=3,                                 # Beam search ë¹„í™œì„±í™” (greedy decoding)
    #     compression_ratio_threshold=float('inf'),    # ê¸¸ì´ ì œí•œ ì—†ìŒ (ì§¤ë¦¬ëŠ” ê²ƒ ë°©ì§€)
    #     logprob_threshold= -5,                       # í™•ë¥  ê¸°ì¤€ ë¹„í™œì„±í™”
    #     no_speech_threshold=0.5                      # ë¬´ìŒ ì œê±° ê¸°ì¤€ ë¹„í™œì„±í™”
    # )
    result = model.transcribe(
        vocals_path,
        word_timestamps=True,
        language="en",
        temperature=0.0,
        best_of=3,
        beam_size=3,
        compression_ratio_threshold=float('inf'),
        logprob_threshold=-5,
        no_speech_threshold=0.5
    )

    segments = result.get("segments", [])
    print(f"ğŸ“ ì´ {len(segments)} ê°œì˜ ë¬¸ì¥ ì¶”ì¶œ.")

    # ê° segment ë‚´ ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ ê²€ì‚¬ ë° ë³´ì •
    for seg in segments:
        words = seg.get('words', [])
        fixed_words = validate_and_fix_timestamps(words)
        seg['words'] = fixed_words

        # â”€â”€ ğŸ”» ì¶”ê°€: ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ì¬ë¶„í•  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # refined = []
    # for seg in segments:
    #     refined.extend(
    #         split_long_segment(seg,
    #                            max_len=4.0,        # 8ì´ˆ ì´ˆê³¼ë©´ ë¶„í• 
    #                            pause_thresh=0.30)  # 0.3ì´ˆ ë¬´ìŒ ê¸°ì¤€
    #     )
    
    # print(f"ğŸ“ 2ì°¨(ë¶„í•  í›„) ì„¸ê·¸ë¨¼íŠ¸ {len(refined)}ê°œ")
    
    # # ğŸ”¸ ì—¬ê¸°ì„œ id ë¶€ì—¬ (1ë¶€í„° ìˆœì°¨)
    # for idx, seg in enumerate(refined, start=1):
    #     seg["id"] = idx

    # return refined
    
    return segments

def transcribe_audio_check(vocals_path):
    print("ğŸ™ï¸ìë§‰ì¶”ì¶œ ê¸°ë³¸ ëª¨ë¸ í˜¸ì¶œ ")
    model = wts.load_model("base").to(device)

    print("ğŸ§  ìŒì„± ë°ì´í„° í…ìŠ¤íŠ¸ ë³€í™˜ì¤‘...")
    result = model.transcribe(
        vocals_path, 
        word_timestamps=True,
        language="en"
    )

    segments = result.get("segments", [])
    print(f"ğŸ“ ì´ {len(segments)} ê°œì˜ ë¬¸ì¥ ì¶”ì¶œ.")
    return segments